{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c78be7",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #5e9ca0;\"><span style=\"font-size: 36px;\"><span style=\"background-color: rgb(255, 255, 255); color: rgb(41, 105, 176);\">Pipelines</span><br></span></h1>\n",
    "\n",
    "<img src=\"https://p4.wallpaperbetter.com/wallpaper/586/209/104/grand-canal-rialto-bridge-venice-italy-wallpaper-preview.jpg\"\n",
    "     width=\"1000\"\n",
    "     height=\"401\"\n",
    "     title=\"Fuente: Venecian Canal - www.wallperpaper.es \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32db009",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #054978;\">CONTENIDO</h2>\n",
    "<a id='Notebook'></a>\n",
    "\n",
    "1. [Introducción](#intro)\n",
    "2. [Dataset](#dataset)\n",
    "3. [Análisis](#analisis)\n",
    "4.[Entrenamiento y testeo](#traintest)\n",
    "5.[El Pipeline](#pipeline)\n",
    "6.[Tipos de datos](#typedata)\n",
    "7. [Las columnas adecuadas](#rightcols)\n",
    "8. [El Modelo](#model)\n",
    "9. [Evaluando el modelo](#metrics)\n",
    "10.[Un paso más allá](#beyond)\n",
    "11.[ Conclusiones](#conclusions)\n",
    "12. [Fuentes](#fuentes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d445446",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "<h2 style=\"color: #2e6c80;\">Introducción</h2>\n",
    "\n",
    "Los pipelines (tuberías) son una herramienta extremadamente simple pero muy útil para gestionar flujos de trabajo de machine learning.\n",
    "\n",
    "Una tarea típica de machine learning generalmente implica la preparación de datos EDA. No entraremos en la amplia gama de actividades que componen la preparación de datos aquí, pero hay muchas . \n",
    "\tEstas tareas son conocidas por ocupar una gran parte del tiempo dedicado a cualquier tarea de machine learning.\n",
    "\n",
    "Los pasos que se suelen seguir al trabajar con datos son la limpieza del conjunto de datos se limpia desde un estado inicial potencial de confusión masiva, sin embargo, todavía hay varios menos intensivo pero no por ello menos importantes pasos de preprocesamiento de datos de transformación, tales como la extracción de características , escala característica , y la reducción de dimensionalidad , por nombrar sólo algunos .\n",
    "\n",
    "Tal vez el preprocesamiento requiera solo una de estas transformaciones, como alguna forma de escalado. Pero tal vez necesites encadenar varias transformaciones juntas, y finalmente terminar con un estimador de algún tipo. Aquí es donde los [**pipelines**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de Scikit-learn pueden ser útiles.\n",
    "\n",
    "\n",
    "  <img src=\"https://cdn.hipwallpaper.com/i/17/86/D2LO5h.jpg\"\n",
    " width=\"500\"\n",
    " height=\"401\"\n",
    " title=\"Fuente: pipe tap wallpers | hipwallpers\">\n",
    " \n",
    "Para estas lecciones, volveremos a trabajar con el conjunto de datos de los coches americanos ya que se entiende muy bien lo que se quiere conseguir con cada visualización, que es comprender la relación entre el precio de un automóvil y sus características. \n",
    "\n",
    "### ¡Empecemos!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec0cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.externals\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d730f",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "# 2. Dataset\n",
    "\n",
    "Se pide:\n",
    "- Importa los datasets de entrenamiento y testeo disponibles en la carpeta con el ejercicio.\n",
    "\n",
    "**3 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18149084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb722dbf",
   "metadata": {},
   "source": [
    "<a id='analisis'></a>\n",
    "# 3. Análisis\n",
    "\n",
    "- ### 3.1. ¿De qué tipo son los datos?\n",
    "\n",
    "**1 línea aprox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16258063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303603a",
   "metadata": {},
   "source": [
    "- ### 3.2. ¿Hay algun valor nulo en las columnas?\n",
    "\n",
    "**1 línea aprox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8eeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521c49b",
   "metadata": {},
   "source": [
    "\n",
    "- ### 3.3. ¿Cuáles son los valores de la variable a predecir?\n",
    "\n",
    "Se pide:\n",
    "- Visualiza los distintos valores dentro de la clase `clase_salario`.\n",
    "\n",
    "**1 línea aprox.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc05d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7462725",
   "metadata": {},
   "source": [
    "<a id='traintest'></a>\n",
    "# 4. Entrenamiento y testeo\n",
    "\n",
    "Se pide:\n",
    "- Separa el dataset de entrenamiento y testeo siendo la columna `y_train` e `y_test` equivalentes a la columna `clase_salario`. La función [**`pop()`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pop.html) te puede ser de ayuda.\n",
    "- Vuelve las variables categóricas de la variable a predecir en variables numéricas. La función [**`replace()`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) te puede ayudar.\n",
    "\n",
    "**6 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0413ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ebf4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a7fca",
   "metadata": {},
   "source": [
    "Afortunadamente, este conjunto de datos no tiene valores perdidos. Aunque parece que todas las características son numéricas, en realidad hay algunas características categóricas que debemos identificar. Por el bien de la ilustración, lo tratarémos como si tuvieran valores perdidos. \n",
    "\n",
    "Primero, filtremos algunas características, obviamente inútiles para este dataset, pero lo tendremos como ejemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf801e",
   "metadata": {},
   "source": [
    "<a id='pipeline'></a>\n",
    "# 5. El Pipeline\n",
    "\n",
    "El parámetro principal de una `pipeline` en la que trabajaremos son los \"pasos\". Es decir,una \"lista de (nombre, proceso) que están encadenadas en el orden, con el último objeto un estimador.\n",
    "\n",
    "Ejemplo: \n",
    "<blockquote>\n",
    "    <pre class=\"nd ne nf ng nh ni nj nk\"><span class=\"ic nl md gv nm b df nn no s np\"><span style=\"background-color: rgb(247, 218, 100);\">Pipeline</span>(steps=[(&apos;<span style=\"color: rgb(226, 80, 65);\">nombre del proceso</span>&apos;, <strong>proceso()</strong>),\n",
    "                (&apos;<span style=\"color: rgb(235, 107, 86);\">nombre modelo</span>&apos;, <strong>modelo()</strong>)])</span></pre>\n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22363a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c92465",
   "metadata": {},
   "source": [
    "<a id='typedata'></a>\n",
    "# 6. Tipos de datos\n",
    "\n",
    "En primer lugar, necesitamos definir los transformadores para características tanto numéricas como categóricas. \n",
    "Se adjunta el objeto para trabajar con las columnas numéricas del dataset. Aún nos falta definir lcómo vamos a trabajar con variables categóricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4579fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para las variables numéricas\n",
    "numeric_transformer = Pipeline(\n",
    "                        steps=[\n",
    "                            ('imputer', SimpleImputer(strategy='median')),\n",
    "                            ('scaler', StandardScaler())\n",
    "                        ]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4bee3",
   "metadata": {},
   "source": [
    "Se pide:\n",
    "- Define el nombre del transformador de las variables categóricas.\n",
    "- El primer paso vá a ser el uso de [**`SimpleImputer()`**](https://interactivechaos.com/es/python/function/simpleimputer) para eliminar valores faltantes. La estrategia la dejamos a vuestro criterio.\n",
    "- El siguiente uso que vamos a darle es el uso de [**`LabelEnconding()`**](https://interactivechaos.com/es/manual/tutorial-de-machine-learning/label-encoding). Como este **no acepta** el uso de tuberías usaremos su equivalente [**`OrdinalEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html). Esto nos servirá para codificar las características categóricas. \n",
    "\n",
    "**1 línea aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092394cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0181be",
   "metadata": {},
   "source": [
    "<a id='rightcols'></a>\n",
    "# 7. Las columnas adecuadas\n",
    "\n",
    "Lo siguiente que debemos hacer es especificar qué columnas son numéricas y cuáles son categóricas, para que podamos aplicar los transformadores en consecuencia. \n",
    "Aplicamos los transformadores a las características mediante la propiedad  [**`ColumnTransformer()`**](https://www.it-swarm-es.com/es/python/como-usar-sklearn-column-transformer/809443066/). La cual aplica los procesos a ciertas columnas seleccionadas por nosotros.\n",
    "\n",
    "**3 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04082c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d60a7",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "# 8. El modelo\n",
    "\n",
    "Después de ensamblar nuestro preprocesador de columnas, podemos agregar el modelo, que es el algoritmo de aprendizaje automático. Dado que en este caso, la variable de destino es continua, aplicarémos el modelo de regresión aleatoria de bosque.\n",
    "\n",
    "Se pide:\n",
    "- Crea el pipeline final.\n",
    "\n",
    "Se adjunta un ejemplo [aquí](https://www.analyticslane.com/2019/02/04/automatizacion-del-procesado-de-datos-en-scikit-learn-con-pipeline/).\n",
    "\n",
    "**2 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7bc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da730a7f",
   "metadata": {},
   "source": [
    "Para crear el modelo, similar a lo que solíamos hacer con un algoritmo de aprendizaje automático, usamos la función \"ajustar\" o `fit` de la canalización. \n",
    "\n",
    "Se pide:\n",
    "- Ajusta el modelo y visualiza el resultado con un simple `print`.\n",
    "\n",
    "**2 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afdae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2931c96",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "# 9. Evaluando el modelo\n",
    "\n",
    "###  De estos dos cúal sirve?¿\n",
    "\n",
    "Predice los valores en el dataset de testeo y...elíge.\n",
    "\n",
    "> ¿Cuál crees que es la métrica que nos sirve en nuestro caso?\n",
    "\n",
    "- a) Error Absoluto medio, [MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)\n",
    "\n",
    "- b) Precisión, [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "- c) Precisión de aciertos y fallos , [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "\n",
    "Se pide:\n",
    "- Prueba las 3 métricas y decide.\n",
    "\n",
    "**8 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0128e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192c169",
   "metadata": {},
   "source": [
    "<a id='beyond'></a>\n",
    "# 10. Un paso más allá\n",
    "\n",
    "Qué pasa si cada modelo funciona mejor en una casuística distinta. Es verdad que no nos podemos casar con ningun lenguaje de programación. También debemos de aplicar este concepto a la hora de elegir modelos. Por ello, al igual que hemos visto anteriormente en las tareas `GridSearch` y `BayesianSearch`, por que no hacer un canal para probar distintos modelos y ver cual funciona mejor?\n",
    "\n",
    "Lo que haremos a continuación es construir 3 pipelines , cada una con un estimador diferente (algoritmo de clasificación), usando hiperparámetros predeterminados:\n",
    "\n",
    "- Random Forest...**¡hecho!**\n",
    "- [LightGBM](https://www.kaggle.com/macespinoza/clasificador-simple-lightgbm-espa-ol) para clasificación...\n",
    "- Mi favorito, [XGBoost](https://ichi.pro/es/ejemplo-de-clasificacion-de-etiquetas-multiples-con-multioutputclassifier-y-xgboost-en-python-167986044155807)...\n",
    "\n",
    "Se pide:\n",
    "- Prepara un `Pipeline` para cada modelo basandote en el modelo creado.\n",
    "\n",
    "**4 líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8940a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826442b",
   "metadata": {},
   "source": [
    "> Una vez creados los tres pipes de los modelos. Vamos a entrenarlos mediante la propiedad `fit`. \n",
    "\n",
    "Se pide:\n",
    "- Genera una lista con las distintas \"tuberías\" creadas a partir de los modelos.\n",
    "- Genera un bucle for para ir ajustando cada objeto `pipe` dentro del bucle con la propiedad `fit`.\n",
    "\n",
    "**3 líneas aprox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ec73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c878a",
   "metadata": {},
   "source": [
    "Compara las precisiones de los distintos modelos. Para ello, una vez más ejecutaremos un bucle y calcularemos el resultado de cada modelo.\n",
    "Por último, visualizaremos los resultados.\n",
    "\n",
    "Se pide:\n",
    "- Mediante un bucle for, calcula con la métrica de precisión, el resultado del modelo.\n",
    "-Visualiza los resultados. La métrica [**`accuracy`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) te puede ser de ayuda.\n",
    "- Guarda el modelo que mejor resultado tenga.\n",
    "\n",
    "**7 líneas aprox. líneas aprox.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d00b206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30935502",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "<h2><span style=\"font-family: Arial, Helvetica, sans-serif; color: rgb(41, 105, 176); font-size: 30px;\">\n",
    "    11. Conclusiones</span></h2>\n",
    "    \n",
    "Estamos llegando a la recta final del Segundo modulo. En esta tarea hemos visto el uso de los canales. Cabe tener en cuenta que los `Pipelines` son muy potentes, pero únicamente nos servirán a la hora de trabajar con datos que hayamos trabajado anteriormente y de los cuales sepamos cómo funcionan o de que pecan.\n",
    "\n",
    "Por ejemplo, podríamos usar esta tecnología a la hora de haber creado un modelo chulo con un cliente y debido a los problemas para extraer datos a tiempo real nos vayan entregando los datos de manera periódica (semanal) mediante una API.\n",
    "\n",
    "<img src=\"https://media1.tenor.com/images/de8317df9cded7bc6773ef193f2aaf8a/tenor.gif\"\n",
    " width=\"600\"\n",
    " height=\"250\"\n",
    " title=\"Fuente: Real life pipelines - www.quora.com\">\n",
    " \n",
    "En ese caso, tener un conducto automatizado para poder darle una respuesta rápida al cliente es fundamental.\n",
    "En las próximas publicaciones, veremos estos problemas adicionales y veremos cómo encajar estas piezas para hacer que el uso de las canalizaciones sea mucho más poderoso de lo que parece en nuestro ejemplo inicial.\n",
    "> @Egger, que sepas que has empezado a crear plantillas muy interesantes para poder usar en el futuro en ejemplos reales.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cba14",
   "metadata": {},
   "source": [
    "<a id='fuentes'></a>\n",
    "# 12. Fuentes\n",
    "\n",
    "\n",
    ".\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Gridsearch - <a href=\"https://www.analyticslane.com/2018/07/02/gridsearchcv/\">Analyticslane</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Selecci&oacute;n autom&aacute;tica de modelos - <a href=\"https://www.analyticslane.com/2019/02/18/seleccionar-automaticamente-los-modelos-en-python-con-gridsearchcv/\">Analyticslane</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Pipelines use II - <a href=\"https://medium.com/datos-y-ciencia/gesti%C3%B3n-de-flujos-de-trabajo-de-aprendizaje-autom%C3%A1tico-con-pipelines-de-scikit-learn-parte-2-eeecab194d83\">Medium-MateoMayo</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Pipelines use I - <a href=\"https://medium.com/datos-y-ciencia/gesti%C3%B3n-de-flujos-de-trabajo-de-machine-learning-con-pipelines-de-scikit-learn-parte-1-una-8a37fcc7c1d0\">Medium-MateoMayo</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">ML pipelines - <a href=\"https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html\">KDnugget</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Pandas and UCI dataset - <a href=\"https://www.kaggle.com/kashnitsky/a1-demo-pandas-and-uci-adult-dataset-solution\">Kaggle</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Automatic model selector &ndash; <a href=\"https://www.analyticslane.com/2019/02/18/seleccionar-automaticamente-los-modelos-en-python-con-gridsearchcv/\">AnalyticsLane</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Cleaning data analysis using pandas &amp; pipes &ndash; <a href=\"https://towardsdatascience.com/cleaner-data-analysis-with-pandas-using-pipes-4d73770fbf3c\">Toward Data Science</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">Pipelines &ndash; <a href=\"https://www.cienciadedatos.net/documentos/py06_machine_learning_python_scikitlearn.html\">Cienciadedatos.net</a></span></p>\n",
    "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:0cm;line-height:107%;font-size:11px;font-family:\"Arial\",sans-serif;'><span style=\"font-size: 16px;\">M&eacute;tricas -<a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">Scikit-Learn</a></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a69e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
